\begin{bibunit}[plainnat]

\input{chapters/sampled_metrics.tex}

\input{chapters/temporal.tex}

\input{chapters/sim_clusters.tex}

% \chapter{Joint Optimization of Multiple Objectives on Music Streaming Platforms}
% \cite{rishabh2020multiobjective}

% \chapter{Multitask Mixture of Sequential Experts for User Activity Streams}

\input{chapters/cluster.tex}

\chapter{Другие работы}

\section*{Embedding-based Retrieval in Facebook Search}

Facebook \\

\textbf{Reference:}~\url{https://arxiv.org/abs/2006.11632}

\textbf{Конспект:}~\url{https://vk.com/@papersreaders-embedding-based-retrieval-in-facebook-search} \\

Исторически поиск в Facebook работал на основе Boolean matching model.

В статье авторы делятся опытом перехода к использованию embedding-based системы на этапе отбора кандидатов перед ранжированием. \\

В основе предлагаемого решения модель построения эмбеддингов запросов и документов. \\

Работа наглядно показывает, что даже относительно несложное решение для Embedding-based retrieval показывает существенное улучшение в сравнении с классическим Boolean matching подходом в задаче отбора кандидатов.

\section*{Controllable Multi-Interest Framework for Recommendation}

Alibaba \\

\textbf{Reference:}~\url{https://arxiv.org/abs/2005.09347}

\textbf{Конспект:}~\url{https://vk.com/@papersreaders-controllable-multi-interest-framework-for-recommendation} \\

Современные рекомендательные системы используют историю пользователя для построения вектора, который описывает пользователя и используется для поиска объектов-кандидатов при построении рекомендаций. 

Однако использование единственного вектора для описания пользователя не позволяет уловить его разнообразные интересы. \\

Авторы статьи предлагают решение, которое позволяет представить пользователя в виде набора из К векторов, каждый из которых соответствует некоторому интересу пользователя.

Данный подход позволяет делать рекомендации как более точными так и более разнообразными в сравнении с существующими state-of-the-art подходами.

\section*{PinnerSage: Multi-Modal User Embedding Framework \\ for Recommendations at Pinterest}

Pinterest \\

\textbf{Reference:}~\url{https://arxiv.org/pdf/2007.03634.pdf} \\

Статья от Pinterest про прокачку системы рекомендаций пинов для пользователя. \\

Авторы статьи рассматривают проблемы связанные с представлением пользователя в виде единственного вектора.

Для решения проблем, в статье предлагают представить пользователя в виде набора векторов. \\

Ключевые отличия от предыдущих работ, предлагающих сделать тоже самое:
\begin{enumerate}
    \item количество векторов для пользователя не фиксировано
    \item вектора для пользователей не обучаются совместно с векторами для пинов
\end{enumerate}

Для того чтобы представить пользователя в виде набора векторов, предлагают делать иерархическую кластеризацию активности пользователя за последнее время (вектора пинов получены black-box моделью).

Каждому кластеру ставят в соответствие его важность.  \\

Для рекомендации релевантных пинов берут 3 наиболее важных кластера и ищут похожие пины с помощью приближенного поиска ближ соседей. \\

Как и в большинстве последних статей от Pinterest, авторы рассматривают продакшн решение, поэтому достаточно внимания уделяют вопросу о том как все это тащить в прод.

\section*{Improving Recommendation Quality in Google Drive}

Google \\

\textbf{Reference:}~\url{https://research.google/pubs/pub49272/} \\

Статья про попытки прокачать качество инструмента Quick Access (статья не научная, а просто про опыт и проведенные эксперименты) \\

В целом, то о чем они пишут очень похоже на наш опыт и на наши эксперименты за последние года полтора. \\

Эксперименты описанные в статье, которые похожие на наши
\begin{itemize}
    \item автоматизация пайплайнов переобучения моделей
    \item попытки затащить DL модели (в статье наоборот пытаются перейти к GBDT)
    \item изучение того как влияет latency на метрики
    \item несколько примеров feature engineering'a 
    \item эксперимент с увеличением числа кандидатов для ранжирования
    \item фича мониторинг
\end{itemize}

\section*{Managing Diversity in Airbnb Search}

\textbf{Reference:}~\cite{abdool2020managing} \\

С продуктовой точки зрения, показ пользователю разнообразных (diverse) рекомендаций ведет к улучшению пользовательского опыта.

Однако, современные модели ранжирования обучаются, оптимизируя relevance, что приводит к однообразным результатам в рекомендациях. \\

В статье авторы численно проверяют предположение о том, что рекомендации довольно часто бывают однообразными, и предлагают метрику Mean Listing Relevance (MLR), которая позволяет оценить как релевантность объектов в выдаче, так и их разнообразие. 

В основе предложенной метрики --- вычисление расстояний между объектами. \\

В работе предложено большое количество способов как можно вычислить расстояние между двумя объектами и то как оптимизировать MLR. \\

В заключении, авторы приводят результаты оффлайн и онлайн экспериментов где показывают рост как привычных для задачи ранжирования метрик, так и метрик связанных с разнообразием.

\section*{Disentangled Self-Supervision in Sequential Recommenders}

Alibaba \\

\textbf{Reference:}~\url{http://pengcui.thumedialab.com/papers/DisentangledSequentialRecommendation.pdf}

\textbf{Keywords:} sequence model, contrastive learning \\

Новое sota решение в задаче sequential recommendations. Бьет BERT4Rec (на некоторых датасетах очень сильно).

Судя по оптимизируемому лоссу, обучаться модель должна быстрее чем BERT4Rec.

Жаль, что авторы не выложили исходный код.

% \addcontentsline{toc}{chapter}{Литература}
\putbib[refs_recsys]
\end{bibunit}
